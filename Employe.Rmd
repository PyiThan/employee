---
title: "Progress Report II"
author: "Pyimoe Than"
date: "4/20/2022"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## library

```{r}
library(dplyr)
library(tidyr)
library(ggplot2)
library(glmnet)
library(pls)
library (e1071)
library(corrplot)
library(tree)
library(ipred)
library(rpart)
library(gam)
library(randomForest)
library(gbm)
```

## importing, renaming, and cleaning data

```{r}
HR=read.csv("HR_comma_sep.csv",header=T)
dim(HR)
str(HR)
HR=rename(HR,department=sales)
HR=HR %>% arrange(desc(department))
str(HR)
```

## Check missing values

```{r}
sum(is.na(HR$satisfaction_level))
sum(is.na(HR$last_evaluation))
sum(is.na(HR$number_project))
sum(is.na(HR$average_montly_hours))
sum(is.na(HR$time_spend_company))
sum(is.na(HR$Work_accident))
sum(is.na(HR$left))
sum(is.na(HR$promotion_last_5years))
sum(is.na(HR$department))
sum(is.na(HR$salary))
```

## Converting data

```{r}

HR$department=factor(HR$department,levels=sort(unique(HR$department)))

HR$Work_accident=factor(HR$Work_accident,levels=sort(unique(HR$Work_accident)))

HR$promotion_last_5years=factor(HR$promotion_last_5years,levels=sort(unique(HR$promotion_last_5years)))

HR$salary=factor(HR$salary,levels=sort(unique(HR$salary)))

HR$time_spend_company=as.numeric(HR$time_spend_company)
HR$number_project=as.numeric(HR$number_project)
HR$average_montly_hours=as.numeric(HR$average_montly_hours)
str(HR)
```

## Explanatory data analysis

```{r}
ggplot(data=HR)+geom_bar(mapping=aes(x=promotion_last_5years,fill=promotion_last_5years))+
  labs(title="Number of employees who get promotion in the last 5 years",subtitle="0(means No promotion), 1(means Yes promotion)")

ggplot(data=HR)+geom_bar(mapping=aes(x=left,fill=left))+
  labs(title="Number of employees stay or left the company",subtitle="0(means did not leave the company), 1(means leave the company)")

ggplot(data=HR)+geom_bar(mapping=aes(x=salary,fill=salary))
ggplot(data=HR)+geom_bar(mapping=aes(x=department,fill=department))+
   theme(axis.text.x=element_text(angle=45))+
  labs(title="Department")


ggplot(data=HR)+geom_boxplot(mapping=aes(x=left,y=satisfaction_level))
ggplot(data=HR)+geom_boxplot(mapping=aes(x=left,y=promotion_last_5years))
ggplot(data=HR)+geom_boxplot(mapping=aes(x=left,y=last_evaluation))
#number of project vs left
ggplot(data=HR)+geom_boxplot(mapping=aes(x=left,y=number_project))
ggplot(data=HR)+geom_boxplot(mapping=aes(x=left,y=average_montly_hours))
ggplot(data=HR)+geom_boxplot(mapping=aes(x=left,y=time_spend_company))
##############################################################################
#employees in which department stay longer
ggplot(data=HR)+geom_boxplot(mapping=aes(x=department,y=time_spend_company,fill=department))+
  theme(axis.text.x=element_text(angle=45))
#employees in which department get highest satisfaction level
ggplot(data=HR)+geom_boxplot(mapping=aes(x=department,y=satisfaction_level,fill=department))+
  theme(axis.text.x=element_text(angle=45))
#employee in which department do more project
ggplot(data=HR)+geom_boxplot(mapping=aes(x=department,y=number_project,fill=department))+
  theme(axis.text.x=element_text(angle=45))
###############################################################################

#concern about employee in which department stay longer
HR_table=HR %>% group_by(department) %>%
  summarize(average_time_spend_company=mean(time_spend_company),average_satisfication_level=mean(satisfaction_level),average_number_project=mean(number_project)) %>%
  arrange(desc(average_time_spend_company,average_satisfication_level))
#which department get a lowest satisfaction level
HR_table=HR %>% group_by(department) %>%
  summarize(average_satisfication_level=mean(satisfaction_level)) %>%
  arrange(desc(average_satisfication_level))
#which department do more project
HR_table=HR %>% group_by(department) %>%
  summarize(average_number_project=mean(number_project)) %>%
  arrange(desc(average_number_project))
#correlation
HR_corr=HR%>%
  select(satisfaction_level,last_evaluation,number_project,average_montly_hours,time_spend_company)
M=cor(HR_corr)
M
corrplot(M,method='color',addCoef.col = 1)
```

## Creating training and testing data

```{r}
train = sample(dim(HR)[1], dim(HR)[1]*0.8)
test=-train
HR.test=HR[test,]
HR.train=HR[train,]
```

## Check for Normality

```{r}
hist(HR$time_spend_company)

#If the data is normally distributed, the points in a Q-Q plot will be on a straight diagonal line.

qqnorm(HR$time_spend_company)
qqline(HR$time_spend_company)
```

From the graph above, the response variable time_spend_company doesn't follow the normality.

## fit the linear model using lest squares on the training set, and report the test error obtained

```{r}
lm.fit=lm(time_spend_company~satisfaction_level+last_evaluation+number_project+average_montly_hours+Work_accident+promotion_last_5years+salary+department,data=HR.train)
summary(lm.fit)
lm.pred=predict(lm.fit,HR.test)
summary(lm.pred)
mean((lm.pred-HR.test$time_spend_company)^2) #test MSE
sqrt(mean((lm.pred-HR.test$time_spend_company)^2)) #RMSE
#our prediction is 1.446 away from the test value.
```

##Fit a ridge regression model on the training set, with lambda chosen by cross validation. Report the test error obtained.

```{r}
train.mat<-model.matrix(time_spend_company~satisfaction_level+last_evaluation+number_project+average_montly_hours+Work_accident+promotion_last_5years+salary+department,data=HR.train)

test.mat<-model.matrix(time_spend_company~satisfaction_level+last_evaluation+number_project+average_montly_hours+Work_accident+promotion_last_5years+salary+department,data=HR.test)

grid<-10^seq(10,-2,length=100)

ridge.fit<-glmnet(train.mat,HR.train$time_spend_company,alpha=0,lambda=grid)

cv.out<-cv.glmnet(train.mat,HR.train$time_spend_company,alpha=0)

bestlam<-cv.out$lambda.min

bestlam

ridge.pred<-predict(ridge.fit,s=bestlam,newx=test.mat)
mean((ridge.pred-HR.test$time_spend_company)^2)
sqrt(mean((ridge.pred-HR.test$time_spend_company)^2))
```

## Fit a lasso regression model on the training set, with lambda chosen by cross validation. Report the test error obtained.

```{r}
train.mat<-model.matrix(time_spend_company~satisfaction_level+last_evaluation+number_project+average_montly_hours+Work_accident+promotion_last_5years+salary+department,data=HR.train)

test.mat<-model.matrix(time_spend_company~satisfaction_level+last_evaluation+number_project+average_montly_hours+Work_accident+promotion_last_5years+salary+department,data=HR.test)

grid<-10^seq(10,-5,length=100)

lasso.fit<-glmnet(train.mat,HR.train$time_spend_company,alpha=1,lambda=grid)
#use cross validation to figure out which lambda value gives smallest MSE.
cv.out<-cv.glmnet(train.mat,HR.train$time_spend_company,alpha=1)
bestlam<-cv.out$lambda.min
#lambda value that gives the smallest MSE
bestlam

lasso.pred<-predict(lasso.fit,s=bestlam,newx=test.mat)
mean((lasso.pred-HR.test$time_spend_company)^2) #MSE
sqrt(mean((lasso.pred-HR.test$time_spend_company)^2)) #RMSE
```

## fit a PCR model on the training set, with M chosen by cross validation. Report the test error obtained, along with the value of M selected by cross-validation

```{r}
set.seed(1)
pcr.fit=pcr(time_spend_company~satisfaction_level+last_evaluation+number_project+average_montly_hours+Work_accident+promotion_last_5years+salary+department,data=HR.train,scale=TRUE,validation="CV")

validationplot(pcr.fit,val.type="MSEP")
#the lowest cv error occurs when M=6
pcr.pred=predict(pcr.fit,HR.test,ncomp=6)
mean((pcr.pred-HR.test$time_spend_company)^2)
sqrt(mean((pcr.pred-HR.test$time_spend_company)^2))
```

## fit a PLS model on the training set with M chosen by cross validation. Report the test error obtained, along with the value of M selected by cross validation

```{r}
set.seed(1)
pls.fit=plsr(time_spend_company~satisfaction_level+last_evaluation+number_project+average_montly_hours+Work_accident+promotion_last_5years+salary+department,data=HR.train,scale=TRUE,validation="CV")
validationplot(pls.fit,val.type="MSEP")
#the lowest cv error occurs when M=4
pls.pred=predict(pls.fit,HR.test,ncomp=4)
mean((pls.pred-HR.test$time_spend_company)^2)
sqrt(mean((pls.pred-HR.test$time_spend_company)^2))
```

## fit a model on the training set using decision trees

```{r}
set.seed(1)
library(tree)
attach(HR)
tree.HR=tree(time_spend_company~satisfaction_level+last_evaluation+number_project+average_montly_hours+Work_accident+promotion_last_5years+salary+department,subset=train)
plot(tree.HR)
text(tree.HR, pretty=0)
summary(tree.HR)
cv.HR=cv.tree(tree.HR)
plot(cv.HR$size,cv.HR$dev,type='b')
prune.HR=prune.tree(tree.HR,best=4)
plot(prune.HR)
text(prune.HR,pretty=0)
yhat=predict(tree.HR,newdata=HR[-train,])
HR.test=HR[-train,"time_spend_company"]
plot(yhat,HR.test)
abline(0,1)
mean((yhat-HR.test)^2)
sqrt(mean((yhat-HR.test)^2))
```

## Bagging.

```{r}
set.seed(1)
bag.HR = randomForest(time_spend_company~satisfaction_level+last_evaluation+number_project+average_montly_hours+Work_accident+promotion_last_5years+salary+department, data=HR.train, mtry = 8, ntree = 100, importance=TRUE)
bag.pred = predict(bag.HR, HR.test)
MSE=mean((HR.test$time_spend_company - bag.pred)^2)
RMSE=sqrt(MSE)
RMSE

importance(bag.HR)
```

## RMSE=1.1100 #Using the importance() function, all the variables are important.
